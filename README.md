# ğŸš² Paris-EcoTrack: End-to-End ELT Pipeline
**A Cloud Data Engineering project correlating Velib' (Bike-sharing) usage with real-time weather data in Paris.**

---

## ğŸ“Œ Overview
This project demonstrates a complete **ELT (Extract, Load, Transform)** pipeline. It automates the collection of bike availability data from the JCDecaux API and weather conditions from OpenWeatherMap, loads them into **Snowflake**, and transforms them using **dbt** into an Analytics-ready Star Schema.

## ğŸ— Architecture


1. **Extract & Load (Python)**: Custom scripts fetch JSON data from REST APIs and load it into Snowflake `RAW` tables using the `write_pandas` connector.
2. **Transform (dbt)**: 
   - **Staging Layer**: Cleaning, casting, and renaming raw fields into clean Views.
   - **Marts Layer**: Modeling a **Star Schema** with a unified Fact table (`fact_eco_mobility`) and a Dimension table (`dim_stations`).
3. **Storage (Snowflake)**: Cloud Data Warehouse utilizing multi-layered schemas (`RAW`, `STAGING`, `ANALYTICS`).
4. **Visualization**: (Optional) Ready to be connected to Power BI or Tableau.

## ğŸ›  Tech Stack
- **Language**: Python 3.x (Pandas, Requests)
- **Data Warehouse**: Snowflake
- **Transformation**: dbt (Data Build Tool)
- **Orchestration**: Environment variables (.env) & Git
- **APIs**: JCDecaux Open Data, OpenWeatherMap

## ğŸ“‚ Project Structure
```text
Paris-EcoTrack/
â”œâ”€â”€ src/                        # Python Extraction Scripts
â”‚   â”œâ”€â”€ extract_velib.py
â”‚   â””â”€â”€ extract_weather.py
â”œâ”€â”€ dbt_project/                # dbt Project Folder
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/            # Data Cleaning (Views)
â”‚   â”‚   â””â”€â”€ marts/              # Star Schema (Tables)
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â””â”€â”€ profiles.yml            # Snowflake connection config
â”œâ”€â”€ .env                        # Credentials (ignored by Git)
â””â”€â”€ requirements.txt            # Dependencies
